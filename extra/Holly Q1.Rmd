---
title: "Holly-Plot1"
author: "Holly Cui"
date: "9/29/2021"
output: github_document
---
## Question 1 <- Update title to relate to the question you’re answering

### Introduction

We want to explore the trends in how the ads change over the years in terms of content, 
audience preferences, and engagement. To analyze the change in content we use the logical variables `funny`,`danger`,`use_sex`,`patriotic`,`show_product_quickly`, `celebrity`, and `animals`. 
To explore audience preference and engagement, `like_count`, `comment_count`, and `view_count` are 
used to calculate ratio of like/engagement over total views.

Many things have changed in the first 20 years of the 21st century. There are life science breakthroughs, 
political conflicts, feminist movements, etc. Therefore, we want to see if people’s reaction to Super Bowl 
commercials reflect the changes in their lifestyles and thoughts over the years. The changes in the ads 
themselves may also tell how companies are reacting to audience preferences.

### Approach

We first used a stacked area chart to see how the proportion of each video 
feature changes over years. Here, a stacked area chart is used because, with 
continuous lines connecting and separating the elements in same group, it is 
visually compatible when we plan to have year (a time variable) as our x axis.
More specifically, over the years on the x axis, we can compare the relative 
percentage change of each feature on the y axis with areas divided by lines 
linking them together. In the stacked area chart, the percentage or proportion of each video feature is 
calculated by first counting the total number of TRUE-valued Boolean variable in 
each year ("funny", "patriotic", etc.), and then generate a dataframe with all 21 
years together. 

First, we used a line graphs faceted by `feature`, a variable that is created using
all logical variables in the data set. The faceted line graph is suitable for time-dependent
changes by each categorical variable. Because the logical variables are either true or
false, 2 different lines in each sub-plot clearly show how the trends (audience
preference in this case) differ if an ad contains a feature or not.

```{r load libraries}
library(tidyverse)
library(lubridate)
library(dplyr)
library(ggrepel)
library(viridis)
library(hrbrthemes)
youtube <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-03-02/youtube.csv', show_col_types = FALSE)


install.packages("wordcloud2")
```

```{r}
youtube <- readr::read_csv('/home/guest/Project 1/data/youtube.csv', show_col_types = FALSE)
```


### Analysis
```{r STACKED-BAR-CHART}

# First, create a function that returns total count of a specific feature in one year.
count_feature_number <- function(data, feature_name, desired_year){
  count1 = 0
  for (i in seq(1, nrow(data))){
    if (data$year[i] == desired_year){
      if (data[i, feature_name] == TRUE){
        count1 = count1 + 1
      }
    }
  }
  return(count1)
}


# With help from the counter above, we define a new function that creates a 
## generalized feature counting dataframe for a single year.
generator <- function(data, year){
  funny_count = count_feature_number(data, "funny", year) 
  show_quickly_count = count_feature_number(data, "show_product_quickly", year)
  patriotic_count = count_feature_number(data, "patriotic", year)
  celebrity_count = count_feature_number(data, "celebrity", year)
  danger_count = count_feature_number(data, "danger", year)
  animals_count = count_feature_number(data, "animals", year)
  use_sex_count = count_feature_number(data, "use_sex", year)
  
  year_value <- rep(year, 7)
  count_of_feature <- c(funny_count, show_quickly_count, patriotic_count, 
                        celebrity_count, danger_count, animals_count, use_sex_count)
  features <- c("Funny", "Show product quickly", "Patriotic", 
                "Celebrity", "Danger", "Animals", "Use sex")
  year_table <- cbind(year_value, count_of_feature, features)
  year_df <- as.data.frame(year_table)
  return(year_df)
}


# Then, using the "appender" function below to get the final dataframe for 
## all years from 2000 to 2020. 
appender <- function(data){
  year_general_df <- generator(data, 2000)
  for (j in seq(2001, 2020)){
    year_general_df <- rbind(year_general_df, 
                             generator(data, j))
  }
  return(year_general_df)
}


# Use the function and get our desired plot
year_feature_df <- appender(youtube)

year_feature <- year_feature_df %>%
  mutate(
    year_value = as.numeric(as.character(year_value)),
    count_of_feature = as.numeric(as.character(count_of_feature))
  ) %>%
  group_by(year_value, features) %>%
  summarise(n = sum(count_of_feature)) %>%
  mutate(percentage = n / sum(n))

# Plot stacked area chart
ggplot(year_feature, aes(x = year_value, y = percentage, fill = features)) + 
    geom_area(alpha=0.6 , size=.5, colour="white") +
    scale_y_continuous(labels = label_percent(accuracy = NULL, scale = 100, 
                                              prefix = "", suffix = "%", 
                                              big.mark = " ", 
                                              decimal.mark = ".", 
                                              trim = TRUE)) +
    labs(
      x = "Year", 
      y = "Percentage", 
      fill = "Features",
      title = "Percentage comparison among video features in\nSuperbowl commercials over years (2000~2020)",
      subtitle = "By video features"
    ) + 
    theme_ipsum() +
    scale_fill_brewer(palette = "Dark2") +
    theme(
      plot.title = element_text(hjust = 0, size = 13)
    )

```


```{r TIME-SERIES-PLOT}
# wrangle data grouped by year
youtube2 <- youtube1 %>%
  drop_na(year, view_count, like_count, dislike_count) %>%
  group_by(year) %>%
  summarise(sum_view = sum(view_count), sum_like = sum(like_count), sum_dislike = sum(dislike_count))
youtube2

# ratio: `like/view` and `dislike/view`
youtube3 <- youtube2 %>%
  mutate(
    like_view_rate = sum_like/sum_view, 
    dislike_view_rate = sum_dislike/sum_view
  )
youtube3

# Initial thought: a pure geom_line plot with view-count vs. year
ggplot(youtube3, aes(x = year, y = sum_view)) +
  geom_line() + 
  labs(
    title = "sum_view"
  )
# However, from the plot, we saw point for 2012 has extremely higher value than points for other years. 
# This reminds us to take like_count and dislike_count into account and average on the total view count to see if the "outlier" can be balanced. 

# Plot ratio plot
ggplot(youtube3, aes(x = year)) +
  geom_line(aes(y = like_view_rate)) +
  labs(
    title = "like/view ratio"
  )
ggplot(youtube3, aes(x = year)) +
  geom_line(aes(y = dislike_view_rate), color = "red") +
  labs(
    title = "dislike/view ratio"
  )
# From the two lines (the reason why they are not put on the same plot is because of different scale of y axis), 
# we can see the outlier has been balanced. The pattern is different, which should be taken into account. 

# The final plot: 
ggplot(data = youtube3, aes(x = year, y = sum_view)) +
  geom_line(aes(size = like_view_rate), color = "blue") +
  stat_smooth(
  color = "red", fill = "grey",
  linetype = "dashed",
  method = "loess"
  ) +
  labs(
    y = "Total number of view",
    title = "Total number of view of Superbowl commercials over years",
    subtitle = "with like/view rate as weight on size",
    size = "like / view"
  )
# The final plot takes into account three different aspects: the sum_view over years, sum of like count averaged on total view count, and the regression smoothed line with confidence interval. 

```




```{r PIE-CHART}
# Find the total number of TRUE values in each Boolean variable
funny_true_count = length(youtube1$funny[youtube1$funny == TRUE])
showproduct_true_count = length(youtube1$show_product_quickly[youtube1$show_product_quickly == TRUE])
patriotic_true_count = length(youtube1$patriotic[youtube1$patriotic == TRUE])
celebrity_true_count = length(youtube1$celebrity[youtube1$celebrity == TRUE])
danger_true_count = length(youtube1$danger[youtube1$danger == TRUE])
animals_true_count = length(youtube1$animals[youtube1$animals == TRUE])
use_sex_true_count = length(youtube1$use_sex[youtube1$use_sex == TRUE])
# Make a new dataframe based on the elements
youtube_pie_df <- tibble(
  category = c("Funny", "Show product quickly", "Patriotic", "Celebrity", "Danger", "Animals", "Use sex"),
  count = c(funny_true_count, showproduct_true_count, patriotic_true_count, celebrity_true_count, 
            danger_true_count, animals_true_count, use_sex_true_count)
)
# Compute the position of labels on the pie chart
youtube_pie_df <- youtube_pie_df %>% 
  arrange(desc(category)) %>%
  mutate(
    ypos = cumsum(count)- 0.5*count, 
    perc = count / sum(count) * 100, 
    percentage = paste0(round(perc, digits = 1), "%") 
    # create new variable regarding the proportion that each element takes up among total
    ) 

# Plot the chart
ggplot(youtube_pie_df, aes(x="", y=count, fill=category)) +
  geom_bar(stat="identity", width=1, color="white") +
  coord_polar("y", start=0) +
  theme_void() +
  geom_text(aes(y = ypos, label = percentage), color = "black", size=3.5) +
  scale_fill_brewer(palette="Pastel2") +
  labs(
    title = "Count of use of the elements included in\nSuperbowl Commercials", 
    fill = "Element include"
  ) +
  theme(
   plot.title = element_text(face = "bold", size = 12, hjust = 0.5)
  )
```

### Discussion

Since question 1 includes two parts: ads contents and audience preferences, our 
analysis also use a binary approach. 

We first looked at audience preference of various attributes in ads. 
In certain years, audience feel strongly about ads that contain specific attributes.
In 2010, ads that contain `animals` element are liked more than 3 times compared 
to ads that do not contain animals. Same observation is shown for ads containing
`patriotic` element in 2010. However, from 2017 to 2020, ads that contain `patriotic`
content become less liked. Ads that use sexuality are far more liked in 2004 but 
are less liked in 2015. In 2002, the ads that have no humorous element are liked 
almost 3 times as ads that have humorous element. 

In the stacked area chart, we get information from the objective nature of the ads.
Over the years, `funny` and `show_product_quickly` take up the highest proportion 
among the seven video attributes. `patriotic` takes up the least proportion 
overall. In fact, most points of intersection, which represents no use of the 
corresponding attribute in one year, appear in the `patriotic` section.
`danger` and `celebrity` share relatively small proportion among all attributes 
stably over years.  

Comparing the line graphs with the stacked area plot, we discover interesting 
matches and unmatches between attributes proportion and audience reactions 
toward them. For example, a corresponding match appears in attribute `celebrity`,
where celebrity-included ads become popular since 2015, which coincides with the 
increasing audience preference. However, things are not always matched. When 
the proportion of `funny` videos grow from 2000 to 2003, audience tend to 
prefer the videos that do not contain humor. Similarly, `danger` in the last 5 
years has narrowed its width in the stacked area chart while audience tends to 
hit like more often for ads containing danger. There can be many underlying 
reasons, but our guesses reside on the different expectations between audience 
and ad companies, or relevant regulations and policies that prevent companies 
from catering to their audience all the time.

A qualification regarding our dataset is that the variable `year` denotes the 
Superbowl year where the commercial was shown. However, some commercials have 
a different published date on Youtube. Furthermore, the youtube videos have been
collected from random Youtube users instead of influencers or official commercial 
accounts. Therefore, the views, likes, and engagement an ad receives also depend 
on the uploader itself.













